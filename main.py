#!/usr/bin/env python3
"""
ç²¾ç®€ç‰ˆå›¾åƒæ‰“æ ‡ç³»ç»Ÿ - æ”¹è¿›çš„å½’ä¸€åŒ–åŠŸèƒ½
"""

import gradio as gr
import os
import json
import time
import re
from pathlib import Path
from typing import Dict, List, Tuple
import pandas as pd
from datetime import datetime
import base64
from PIL import Image
import io
from chat_tool import AIChatTool, ModelType


# ç®€å•çš„æ—¥å¿—è®°å½•
def log_info(message):
    print(f"[INFO] {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {message}")


def log_error(message):
    print(f"[ERROR] {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {message}")


class SimpleImageLabelingSystem:
    def __init__(self):
        # æ ¸å¿ƒæ•°æ®
        self.current_folder = ""
        # ä¿å­˜æ‰«æåˆ°çš„å›¾ç‰‡
        self.images = []
        self.labels = {}

        # å½’ä¸€åŒ–ç›¸å…³
        self.normalization_analysis = None
        self.normalization_preview = {}

        # AIæ‰“æ ‡æ¨¡å—
        # self.ai_labeler = AILabeler()
        self.ai_chat_tool = AIChatTool()
        self.tag_normalizer = TagNormalizer(self.ai_chat_tool)
        # self.translator = Translator()
        self.dataset_manager = DatasetManager()

        # é…ç½®
        self.config = {
            'labeling_prompt': self._default_labeling_prompt(),
            'translation_prompt': self._default_translation_prompt(),
            'model_type': 'GPT',
            'delay_between_calls': 2.0
        }

        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        self.supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp'}

    def _default_labeling_prompt(self) -> str:
        """é»˜è®¤çš„æ‰“æ ‡æç¤ºè¯"""
        return """ä½ æ˜¯ä¸€åå›¾åƒç†è§£ä¸“å®¶ï¼Œè¯·æ ¹æ®ä»¥ä¸‹å›¾ç‰‡å†…å®¹ï¼Œç”Ÿæˆä¸€å¥è‡ªç„¶æµç•…ã€å…·ä½“æ¸…æ™°çš„å›¾åƒæè¿°ã€‚è¦æ±‚å¦‚ä¸‹ï¼š
                1. ä½¿ç”¨ç®€æ´å‡†ç¡®çš„ä¸­æ–‡å¥å­ï¼›
                2. æè¿°åº”åŒ…æ‹¬å›¾åƒä¸­çš„ä¸»ä½“ã€åŠ¨ä½œã€ä½ç½®æˆ–èƒŒæ™¯ç¯å¢ƒï¼›
                3. é¿å…ä½¿ç”¨"å›¾ä¸­"ã€"è¿™æ˜¯ä¸€å¼ å›¾ç‰‡"ç­‰å†—ä½™æªè¾ï¼›
                4. è¯­è¨€é£æ ¼è‡ªç„¶ã€å…·è±¡ï¼Œä¸ä½¿ç”¨æŠ½è±¡å½¢å®¹è¯æˆ–ä¸»è§‚æ„Ÿå—ï¼›
                5. æè¿°çš„ç»“æ„ä¸º[ä¸»ä½“] + [å¤–è§‚/æœè£…] + [åŠ¨ä½œ/å§¿åŠ¿] + [èƒŒæ™¯/ç¯å¢ƒ] + [æ°›å›´/ç¯å…‰ï¼ˆå¯é€‰ï¼‰]
                
                ç°åœ¨è¯·æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼š"""

    def _default_translation_prompt(self) -> str:
        """é»˜è®¤çš„ç¿»è¯‘æç¤ºè¯"""
        return """è¯·å°†ä»¥ä¸‹ä¸­æ–‡æè¿°ç¿»è¯‘æˆè‹±æ–‡ï¼Œä¿æŒåŸæ„ä¸å˜ï¼Œè¦æ±‚ï¼š
                1. ç¿»è¯‘è¦å‡†ç¡®ã€è‡ªç„¶ã€æµç•…
                2. ä¿æŒåŸæ–‡çš„æè¿°é¡ºåºå’Œé‡ç‚¹
                3. ä½¿ç”¨é€‚åˆAIç»˜ç”»çš„æè¿°é£æ ¼
                4. ç›´æ¥è¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸è¦åŠ ä»»ä½•é¢å¤–è¯´æ˜
                
                ä¸­æ–‡æè¿°ï¼š"""

    def scan_images(self, folder_path: str) -> Tuple[List[str], str]:
        """æ‰«ææ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡"""
        try:
            if not os.path.exists(folder_path):
                return [], "æ–‡ä»¶å¤¹ä¸å­˜åœ¨"

            self.current_folder = folder_path
            self.images = []

            for file in os.listdir(folder_path):
                if Path(file).suffix.lower() in self.supported_formats:
                    img_path = os.path.join(folder_path, file)
                    self.images.append(img_path)

            self.images.sort()
            self.load_existing_labels()

            message = f"æ‰¾åˆ° {len(self.images)} å¼ å›¾ç‰‡"
            log_info(message)

            return self.images, message

        except Exception as e:
            error_msg = f"æ‰«ææ–‡ä»¶å¤¹å‡ºé”™: {str(e)}"
            log_error(error_msg)
            return [], error_msg

    def load_existing_labels(self):
        """åŠ è½½å·²æœ‰çš„æ ‡ç­¾æ–‡ä»¶"""
        self.labels = {}

        for img_path in self.images:
            txt_path = os.path.splitext(img_path)[0] + '.txt'
            label_text = ""

            if os.path.exists(txt_path):
                try:
                    with open(txt_path, 'r', encoding='utf-8') as f:
                        label_text = f.read().strip()
                except Exception as e:
                    log_error(f"è¯»å–æ ‡ç­¾æ–‡ä»¶å¤±è´¥ {txt_path}: {e}")

            self.labels[img_path] = label_text

    def create_image_gallery_html(self) -> str:
        """åˆ›å»ºå›¾ç‰‡å±•ç¤ºHTML"""
        if not self.images:
            return "<p>æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡</p>"

        html_parts = ["<div style='display: flex; flex-wrap: wrap; gap: 10px; padding: 10px;'>"]

        for i, img_path in enumerate(self.images):
            img_name = os.path.basename(img_path)
            current_label = self.labels.get(img_path, "")

            # è¯»å–å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64
            try:
                with Image.open(img_path) as img:
                    # åˆ›å»ºç¼©ç•¥å›¾
                    img.thumbnail((1024, 1024), Image.Resampling.LANCZOS)
                    buffer = io.BytesIO()
                    img.save(buffer, format='JPEG', quality=85)
                    img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
                    img_src = f"data:image/jpeg;base64,{img_base64}"
            except:
                img_src = ""

            # åˆ›å»ºå›¾ç‰‡å¡ç‰‡
            img_container = f"""
            <div style='
                width: 300px;
                border: 1px solid #ddd;
                padding: 10px;
                border-radius: 5px;
                background: white;
            '>
                <div style='text-align: center; margin-bottom: 10px;'>
                    <img src='{img_src}' style='max-width: 100%; max-height: 200px;' alt='{img_name}'/>
                </div>
                <div style='font-weight: bold; margin-bottom: 5px; word-break: break-all;'>
                    {img_name}
                </div>
                <div>
                    <textarea id='label_{i}' 
                              style='width: 100%; height: 80px; resize: vertical;' 
                              placeholder='æ ‡ç­¾å†…å®¹...'
                              readonly>{current_label}</textarea>
                </div>
                <div style='text-align: right; margin-top: 5px; color: {"green" if current_label else "orange"}'>
                    {'âœ“ å·²æ ‡æ³¨' if current_label else 'â—‹ æœªæ ‡æ³¨'}
                </div>
            </div>
            """
            html_parts.append(img_container)

        html_parts.append("</div>")

        # ç»Ÿè®¡ä¿¡æ¯
        labeled_count = len([l for l in self.labels.values() if l.strip()])
        stats_html = f"""
        <div style='background: #f0f0f0; padding: 10px; margin-bottom: 10px; border-radius: 5px;'>
            <h3>æ•°æ®é›†ç»Ÿè®¡</h3>
            <p>æ€»æ•°: {len(self.images)} | å·²æ ‡æ³¨: {labeled_count} | æœªæ ‡æ³¨: {len(self.images) - labeled_count}</p>
        </div>
        """

        return stats_html + ''.join(html_parts)

    def start_ai_labeling(self, prompt: str, model_type: str, delay: float) -> str:
        """å¼€å§‹AIæ‰“æ ‡"""
        try:
            # åªæ ‡æ³¨æœªæ ‡æ³¨çš„å›¾ç‰‡
            unlabeled_images = [img for img in self.images if not self.labels.get(img, "").strip()]

            if not unlabeled_images:
                return "æ‰€æœ‰å›¾ç‰‡éƒ½å·²æ ‡æ³¨"

            success_count = 0

            # é€ä¸ªå¤„ç†å›¾ç‰‡
            for i, img_path in enumerate(unlabeled_images):
                try:
                    # è°ƒç”¨AIè¿›è¡Œæ ‡æ³¨
                    label_text = self.ai_chat_tool.call_chatai(model_type=model_type, prompt=prompt,
                                                               image_path=img_path)
                    # if model_type == "æœ¬åœ°LLM Studio":
                    #     label_text = self.ai_chat_tool.call_chatai(model_type=ModelType.LOCAL, prompt=prompt,
                    #                                                image_path=img_path)
                    # else:  # GPT
                    #     label_text = self.ai_labeler.call_gpt(img_path, prompt)

                    if label_text and not label_text.startswith("é”™è¯¯"):
                        self.labels[img_path] = label_text
                        success_count += 1

                        # ä¿å­˜åˆ°æ–‡ä»¶
                        txt_path = os.path.splitext(img_path)[0] + '.txt'
                        with open(txt_path, 'w', encoding='utf-8') as f:
                            f.write(label_text)

                    log_info(f"å®Œæˆ {i + 1}/{len(unlabeled_images)}: {os.path.basename(img_path)}")

                    # å»¶è¿Ÿé¿å…APIé™åˆ¶
                    if i < len(unlabeled_images) - 1:
                        time.sleep(delay)

                except Exception as e:
                    log_error(f"å¤„ç†å›¾ç‰‡å¤±è´¥ {img_path}: {e}")
                    continue

            return f"AIæ ‡æ³¨å®Œæˆï¼ŒæˆåŠŸæ ‡æ³¨ {success_count}/{len(unlabeled_images)} å¼ å›¾ç‰‡"

        except Exception as e:
            error_msg = f"AIæ ‡æ³¨å¤±è´¥: {str(e)}"
            log_error(error_msg)
            return error_msg

    def analyze_normalization(self, model_type: str) -> Tuple[str, str]:
        """åˆ†æå½’ä¸€åŒ–è§„åˆ™ï¼Œè¿”å›è§„åˆ™æè¿°å’Œå¯¹æ¯”è¡¨æ ¼"""
        try:
            # æ”¶é›†æ‰€æœ‰æ ‡ç­¾
            all_labels = {}
            for img_path, label_text in self.labels.items():
                if label_text and label_text.strip():
                    all_labels[os.path.basename(img_path)] = label_text

            if not all_labels:
                return "æ²¡æœ‰æ ‡ç­¾éœ€è¦å½’ä¸€åŒ–", ""

            # è°ƒç”¨AIåˆ†æéœ€è¦å½’ä¸€åŒ–çš„æ ‡ç­¾
            self.normalization_analysis = self.tag_normalizer.analyze_normalization(all_labels, model_type)

            if isinstance(self.normalization_analysis, dict) and 'normalized_labels' in self.normalization_analysis:
                # ç”Ÿæˆè§„åˆ™æè¿°
                rules_html = self._generate_rules_display()
                # ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
                comparison_html = self._generate_comparison_table()

                return rules_html, comparison_html
            else:
                error_msg = f"åˆ†æå¤±è´¥: {self.normalization_analysis.get('error', 'æœªçŸ¥é”™è¯¯')}"
                return error_msg, ""

        except Exception as e:
            error_msg = f"å½’ä¸€åŒ–åˆ†æå¤±è´¥: {str(e)}"
            log_error(error_msg)
            return error_msg, ""

    def _generate_rules_display(self) -> str:
        """ç”Ÿæˆå½’ä¸€åŒ–è§„åˆ™çš„HTMLæ˜¾ç¤º"""
        if not self.normalization_analysis or 'suggestions' not in self.normalization_analysis:
            return "<p>æ²¡æœ‰æ‰¾åˆ°å½’ä¸€åŒ–å»ºè®®</p>"

        html_parts = ["""
        <div style='background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 10px 0;'>
            <h3 style='color: #2c3e50; margin-bottom: 15px;'>ğŸ” å½’ä¸€åŒ–è§„åˆ™åˆ†æ</h3>
        """]

        suggestions = self.normalization_analysis.get('suggestions', [])

        if suggestions:
            html_parts.append("<div style='margin-bottom: 20px;'>")
            for i, suggestion in enumerate(suggestions, 1):
                rule_item = f"""
                <div style='background: white; padding: 12px; margin: 8px 0; border-left: 4px solid #3498db; border-radius: 4px;'>
                    <h4 style='color: #2980b9; margin: 0 0 8px 0;'>è§„åˆ™ {i}</h4>
                    <p style='margin: 5px 0;'><strong>åŸå§‹è¡¨è¾¾:</strong> {suggestion.get('åŸå§‹', 'N/A')}</p>
                    <p style='margin: 5px 0;'><strong>å»ºè®®ä¿®æ”¹:</strong> {suggestion.get('å»ºè®®', 'N/A')}</p>
                    <p style='margin: 5px 0; color: #7f8c8d;'><strong>ä¿®æ”¹åŸå› :</strong> {suggestion.get('åŸå› ', 'N/A')}</p>
                </div>
                """
                html_parts.append(rule_item)
            html_parts.append("</div>")
        else:
            html_parts.append("<p>æ²¡æœ‰æ‰¾åˆ°éœ€è¦å½’ä¸€åŒ–çš„è§„åˆ™</p>")

        # ç»Ÿè®¡ä¿¡æ¯
        total_labels = len([l for l in self.labels.values() if l.strip()])
        normalized_count = len(self.normalization_analysis.get('normalized_labels', {}))

        stats = f"""
        <div style='background: #e8f5e8; padding: 10px; border-radius: 5px; margin-top: 15px;'>
            <h4 style='margin: 0 0 10px 0; color: #27ae60;'>ğŸ“Š ç»Ÿè®¡ä¿¡æ¯</h4>
            <p style='margin: 5px 0;'>æ€»æ ‡ç­¾æ•°: {total_labels}</p>
            <p style='margin: 5px 0;'>éœ€è¦ä¿®æ”¹çš„æ ‡ç­¾: {normalized_count}</p>
            <p style='margin: 5px 0;'>å½’ä¸€åŒ–è§„åˆ™æ•°: {len(suggestions)}</p>
        </div>
        """
        html_parts.append(stats)
        html_parts.append("</div>")

        return ''.join(html_parts)

    def _generate_comparison_table(self) -> str:
        """ç”Ÿæˆä¿®æ”¹å‰åå¯¹æ¯”è¡¨æ ¼"""
        if not self.normalization_analysis or 'normalized_labels' not in self.normalization_analysis:
            return "<p>æ²¡æœ‰å¯¹æ¯”æ•°æ®</p>"

        normalized_labels = self.normalization_analysis['normalized_labels']

        html_parts = ["""
        <div style='background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 10px 0;'>
            <h3 style='color: #2c3e50; margin-bottom: 15px;'>ğŸ“‹ æ ‡ç­¾ä¿®æ”¹å¯¹æ¯”</h3>
            <div style='overflow-x: auto;'>
                <table style='width: 100%; border-collapse: collapse; background: white; border-radius: 5px; overflow: hidden;'>
                    <thead>
                        <tr style='background: #34495e; color: white;'>
                            <th style='padding: 12px; text-align: left; width: 200px;'>å›¾ç‰‡åç§°</th>
                            <th style='padding: 12px; text-align: left;'>ä¿®æ”¹å‰</th>
                            <th style='padding: 12px; text-align: left;'>ä¿®æ”¹å</th>
                            <th style='padding: 12px; text-align: center; width: 100px;'>çŠ¶æ€</th>
                        </tr>
                    </thead>
                    <tbody>
        """]

        # ç”Ÿæˆå¯¹æ¯”è¡Œ
        for img_path, original_label in self.labels.items():
            if not original_label or not original_label.strip():
                continue

            img_name = os.path.basename(img_path)
            normalized_label = normalized_labels.get(img_name, original_label)

            # åˆ¤æ–­æ˜¯å¦æœ‰å˜åŒ–
            has_changes = original_label != normalized_label
            status_color = "#e74c3c" if has_changes else "#27ae60"
            status_text = "éœ€ä¿®æ”¹" if has_changes else "æ— å˜åŒ–"
            row_bg = "#fff5f5" if has_changes else "#f0fff0"

            row = f"""
            <tr style='background: {row_bg}; border-bottom: 1px solid #ecf0f1;'>
                <td style='padding: 12px; font-weight: bold; word-break: break-word;'>{img_name}</td>
                <td style='padding: 12px; max-width: 300px; word-wrap: break-word;'>{original_label}</td>
                <td style='padding: 12px; max-width: 300px; word-wrap: break-word;'>{normalized_label}</td>
                <td style='padding: 12px; text-align: center;'>
                    <span style='color: {status_color}; font-weight: bold;'>{status_text}</span>
                </td>
            </tr>
            """
            html_parts.append(row)

        html_parts.extend(["""
                    </tbody>
                </table>
            </div>
        </div>
        """])

        return ''.join(html_parts)

    def apply_normalization(self) -> str:
        """åº”ç”¨å½’ä¸€åŒ–ä¿®æ”¹"""
        try:
            if not self.normalization_analysis or 'normalized_labels' not in self.normalization_analysis:
                return "æ²¡æœ‰å¯åº”ç”¨çš„å½’ä¸€åŒ–åˆ†æç»“æœ"

            normalized_labels = self.normalization_analysis['normalized_labels']
            changes_count = 0

            # åº”ç”¨å½’ä¸€åŒ–ç»“æœ
            for img_path in self.images:
                img_name = os.path.basename(img_path)
                if img_name in normalized_labels:
                    new_label = normalized_labels[img_name]
                    if self.labels[img_path] != new_label:
                        self.labels[img_path] = new_label
                        changes_count += 1

                        # ä¿å­˜åˆ°æ–‡ä»¶
                        txt_path = os.path.splitext(img_path)[0] + '.txt'
                        with open(txt_path, 'w', encoding='utf-8') as f:
                            f.write(new_label)

                        log_info(f"å½’ä¸€åŒ–ä¿®æ”¹: {img_name}")

            # æ¸…é™¤åˆ†æç»“æœ
            self.normalization_analysis = None

            return f"âœ… å½’ä¸€åŒ–å®Œæˆï¼æˆåŠŸä¿®æ”¹äº† {changes_count} ä¸ªæ ‡ç­¾"

        except Exception as e:
            error_msg = f"åº”ç”¨å½’ä¸€åŒ–å¤±è´¥: {str(e)}"
            log_error(error_msg)
            return error_msg

    def cancel_normalization(self) -> str:
        """å–æ¶ˆå½’ä¸€åŒ–ä¿®æ”¹"""
        self.normalization_analysis = None
        return "âŒ å·²å–æ¶ˆå½’ä¸€åŒ–æ“ä½œ"

    def translate_labels(self, prompt: str, model_type: str, target_lang: str = "è‹±æ–‡") -> str:
        """ç¿»è¯‘æ ‡ç­¾"""
        try:
            # æ”¶é›†éœ€è¦ç¿»è¯‘çš„æ ‡ç­¾
            labels_to_translate = {}
            for img_path, label_text in self.labels.items():
                if label_text and label_text.strip():
                    labels_to_translate[img_path] = label_text

            if not labels_to_translate:
                return "æ²¡æœ‰æ ‡ç­¾éœ€è¦ç¿»è¯‘"

            success_count = 0

            # é€ä¸ªç¿»è¯‘
            for img_path, original_label in labels_to_translate.items():
                try:
                    # è°ƒç”¨ç¿»è¯‘
                    translated = self.ai_chat_tool.call_chatai(model_type=model_type,prompt=prompt,content=original_label)

                    if translated and not translated.startswith("é”™è¯¯"):
                        # ä¿å­˜ç¿»è¯‘ç»“æœåˆ°æ–°æ–‡ä»¶
                        base_path = os.path.splitext(img_path)[0]
                        translated_file = f"{base_path}_translated.txt"
                        with open(translated_file, 'w', encoding='utf-8') as f:
                            f.write(translated)
                        success_count += 1

                        log_info(f"ç¿»è¯‘å®Œæˆ: {os.path.basename(img_path)}")

                    # çŸ­æš‚å»¶è¿Ÿ
                    time.sleep(0.5)

                except Exception as e:
                    log_error(f"ç¿»è¯‘å¤±è´¥ {img_path}: {e}")
                    continue

            return f"ç¿»è¯‘å®Œæˆï¼ŒæˆåŠŸç¿»è¯‘ {success_count}/{len(labels_to_translate)} ä¸ªæ ‡ç­¾"

        except Exception as e:
            error_msg = f"ç¿»è¯‘å¤±è´¥: {str(e)}"
            log_error(error_msg)
            return error_msg

    def save_dataset(self, format_type: str) -> str:
        """ä¿å­˜æ•°æ®é›†"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

            if format_type == "json":
                # ä¿å­˜ä¸ºJSONæ ¼å¼
                output_file = os.path.join(self.current_folder, f"dataset_{timestamp}.json")
                dataset = {
                    'images': [],
                    'created': timestamp
                }

                for img_path, label in self.labels.items():
                    dataset['images'].append({
                        'filename': os.path.basename(img_path),
                        'path': img_path,
                        'label': label
                    })

                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(dataset, f, ensure_ascii=False, indent=2)

                return f"æ•°æ®é›†å·²ä¿å­˜åˆ°: {output_file}"

            elif format_type == "csv":
                # ä¿å­˜ä¸ºCSVæ ¼å¼
                output_file = os.path.join(self.current_folder, f"dataset_{timestamp}.csv")
                df = pd.DataFrame([
                    {'filename': os.path.basename(path), 'label': label}
                    for path, label in self.labels.items()
                ])
                df.to_csv(output_file, index=False, encoding='utf-8')

                return f"æ•°æ®é›†å·²ä¿å­˜åˆ°: {output_file}"

            else:
                return "ä¸æ”¯æŒçš„æ ¼å¼"

        except Exception as e:
            return f"ä¿å­˜å¤±è´¥: {str(e)}"


# AIæ ‡æ³¨æ¨¡å—
# class AILabeler:
#     def __init__(self):
#         self.llm_studio_url = "http://localhost:1234/v1"
#
#     def encode_image_to_base64(self, image_path: str) -> str:
#         """å°†å›¾ç‰‡ç¼–ç ä¸ºbase64"""
#         try:
#             with Image.open(image_path) as img:
#                 # è°ƒæ•´å¤§å°
#                 max_size = (1024, 1024)
#                 img.thumbnail(max_size, Image.Resampling.LANCZOS)
#
#                 buffer = io.BytesIO()
#                 img.save(buffer, format='JPEG', quality=85)
#                 img_str = base64.b64encode(buffer.getvalue()).decode()
#                 return img_str
#         except Exception as e:
#             log_error(f"å›¾ç‰‡ç¼–ç å¤±è´¥ {image_path}: {e}")
#             return ""
#
#     def call_gpt(self, image_path: str, prompt: str) -> str:
#         """è°ƒç”¨GPTï¼ˆéœ€è¦æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰"""
#         try:
#             # å¯¼å…¥GPTè°ƒç”¨æ¨¡å—
#             from chat_tool import get_completion, encode_image_to_base64
#
#             img_base64 = encode_image_to_base64(image_path)
#             result = get_completion(control="customize", prompt=prompt, content=img_base64)
#
#             return result if result else "GPTè°ƒç”¨å¤±è´¥"
#
#         except Exception as e:
#             log_error(f"GPTè°ƒç”¨é”™è¯¯: {e}")
#             return f"é”™è¯¯: {str(e)}"
#
#     def call_local_llm(self, image_path: str, prompt: str) -> str:
#         """è°ƒç”¨æœ¬åœ°LLM Studio"""
#         try:
#             import requests
#
#             base64_image = self.encode_image_to_base64(image_path)
#             if not base64_image:
#                 return "å›¾ç‰‡ç¼–ç å¤±è´¥"
#
#             payload = {
#                 "model": "gpt-4-vision-preview",
#                 "messages": [
#                     {
#                         "role": "user",
#                         "content": [
#                             {"type": "text", "text": prompt},
#                             {
#                                 "type": "image_url",
#                                 "image_url": {
#                                     "url": f"data:image/jpeg;base64,{base64_image}"
#                                 }
#                             }
#                         ]
#                     }
#                 ],
#                 "max_tokens": 500,
#                 "temperature": 0.3
#             }
#
#             response = requests.post(
#                 f"{self.llm_studio_url}/chat/completions",
#                 json=payload,
#                 timeout=60
#             )
#
#             if response.status_code == 200:
#                 result = response.json()
#                 return result['choices'][0]['message']['content'].strip()
#             else:
#                 return f"æœ¬åœ°LLMè°ƒç”¨å¤±è´¥: {response.status_code}"
#
#         except Exception as e:
#             log_error(f"æœ¬åœ°LLMè°ƒç”¨å¤±è´¥: {e}")
#             return f"é”™è¯¯: {str(e)}"


# æ ‡ç­¾å½’ä¸€åŒ–æ¨¡å—
class TagNormalizer:
    def __init__(self, ai_chat_tool):
        self.ai_chat_tool = ai_chat_tool

    def analyze_normalization(self, labels_dict: Dict[str, str], model_type: str) -> dict:
        """åˆ†æéœ€è¦å½’ä¸€åŒ–çš„æ ‡ç­¾"""
        try:
            # æ„å»ºå‘é€ç»™AIçš„å†…å®¹
            prompt = """è¯·åˆ†æä»¥ä¸‹å›¾åƒæ ‡ç­¾ï¼Œæ‰¾å‡ºéœ€è¦å½’ä¸€åŒ–çš„å†…å®¹ã€‚
                        è¯·è¯†åˆ«ï¼š
                        1. ç›¸ä¼¼æˆ–é‡å¤çš„æè¿°
                        2. å¯ä»¥ç»Ÿä¸€çš„è¡¨è¾¾æ–¹å¼
                        3. éœ€è¦ä¿®æ­£çš„æ ¼å¼é—®é¢˜
                        
                        æ ‡ç­¾åˆ—è¡¨ï¼š
                        """

            for img_name, label in labels_dict.items():
                prompt += f"\n{img_name}: {label}"

            prompt += """è¯·è¿”å›JSONæ ¼å¼çš„å½’ä¸€åŒ–å»ºè®®ï¼Œç¡®ä¿JSONå®Œæ•´ä¸”æ ¼å¼æ­£ç¡®ï¼š
                    {
                        "suggestions": [
                            {"åŸå§‹": "xxx", "å»ºè®®": "yyy", "åŸå› ": "zzz"}
                        ],
                        "normalized_labels": {
                            "å›¾ç‰‡å": "å½’ä¸€åŒ–åçš„æ ‡ç­¾"
                        }
                    }
                    
                    é‡è¦ï¼šè¯·ç¡®ä¿è¿”å›å®Œæ•´çš„JSONï¼Œä¸è¦åŒ…å«å…¶ä»–è¯´æ˜æ–‡å­—ã€‚"""

            # è°ƒç”¨AI
            result = self.ai_chat_tool.call_chatai(model_type=model_type,prompt=prompt)

            # if model_type == "æœ¬åœ°LLM Studio":
            #     result = self._call_local_llm_text(prompt)
            # else:
            #     result = self._call_gpt_text(prompt)

            log_info(f"AIè¿”å›çš„åŸå§‹ç»“æœå‰500å­—ç¬¦: {result[:500]}...")

            # æ”¹è¿›çš„JSONè§£æé€»è¾‘
            parsed_result = self._parse_json_response(result)

            if parsed_result is None:
                log_error("æ— æ³•è§£æAIè¿”å›çš„JSONç»“æœ")
                return {"error": "JSONè§£æå¤±è´¥", "raw_response": result[:200]}

            return parsed_result

        except Exception as e:
            log_error(f"å½’ä¸€åŒ–åˆ†æå¤±è´¥: {e}")
            return {"error": str(e)}

    def _parse_json_response(self, response: str) -> dict:
        """æ”¹è¿›çš„JSONè§£ææ–¹æ³•"""
        try:
            # æ–¹æ³•1: å¯»æ‰¾å®Œæ•´çš„JSONå—
            json_start = response.find('{')
            if json_start == -1:
                log_error("æœªæ‰¾åˆ°JSONå¼€å§‹æ ‡è®°")
                return None

            # å¯»æ‰¾åŒ¹é…çš„ç»“æŸæ‹¬å·
            brace_count = 0
            json_end = -1

            for i in range(json_start, len(response)):
                if response[i] == '{':
                    brace_count += 1
                elif response[i] == '}':
                    brace_count -= 1
                    if brace_count == 0:
                        json_end = i + 1
                        break

            if json_end == -1:
                log_error("æœªæ‰¾åˆ°JSONç»“æŸæ ‡è®°ï¼Œå¯èƒ½è¢«æˆªæ–­")
                return None

            json_str = response[json_start:json_end]
            log_info(f"æå–çš„JSONå­—ç¬¦ä¸²å‰200å­—ç¬¦: {json_str[:200]}...")

            # å°è¯•è§£æJSON
            parsed = json.loads(json_str)

            # éªŒè¯å¿…è¦å­—æ®µ
            if "suggestions" not in parsed and "normalized_labels" not in parsed:
                log_error("JSONç¼ºå°‘å¿…è¦å­—æ®µ")
                return None

            return parsed

        except json.JSONDecodeError as e:
            log_error(f"JSONè§£æé”™è¯¯: {e}")
            return self._try_fix_json(response)
        except Exception as e:
            log_error(f"JSONæå–é”™è¯¯: {e}")
            return None

    def _try_fix_json(self, response: str) -> dict:
        """å°è¯•ä¿®å¤å¸¸è§çš„JSONé—®é¢˜"""
        try:
            json_start = response.find('{')
            if json_start == -1:
                return None

            json_end = response.rfind('}')
            if json_end == -1:
                return None

            json_str = response[json_start:json_end + 1]

            # å°è¯•ä¸€äº›å¸¸è§çš„ä¿®å¤
            fixes = [
                lambda s: s.replace('",}', '"}'),
                lambda s: re.sub(r',(\s*[}\]])', r'\1', s),
                lambda s: s.replace('\\"', '"'),
            ]

            for fix in fixes:
                try:
                    fixed_json = fix(json_str)
                    parsed = json.loads(fixed_json)
                    log_info("JSONä¿®å¤æˆåŠŸ")
                    return parsed
                except:
                    continue

            return None

        except Exception:
            return None

    # def _call_local_llm_text(self, prompt: str) -> str:
    #     """è°ƒç”¨æœ¬åœ°LLMï¼ˆçº¯æ–‡æœ¬ï¼‰"""
    #     try:
    #         import requests
    #
    #         payload = {
    #             "model": "gpt-3.5-turbo",
    #             "messages": [{"role": "user", "content": prompt}],
    #             "max_tokens": 2500,
    #             "temperature": 0.1
    #         }
    #
    #         response = requests.post(
    #             "http://localhost:1234/v1/chat/completions",
    #             json=payload,
    #             timeout=120
    #         )
    #
    #         if response.status_code == 200:
    #             result = response.json()
    #             content = result['choices'][0]['message']['content']
    #
    #             # æ£€æŸ¥æ˜¯å¦è¢«æˆªæ–­
    #             finish_reason = result['choices'][0].get('finish_reason', '')
    #             if finish_reason == 'length':
    #                 log_error("LLMå“åº”è¢«æˆªæ–­ï¼Œè¯·å¢åŠ max_tokens")
    #
    #             return content
    #         else:
    #             log_error(f"LLMè°ƒç”¨å¤±è´¥: {response.status_code}")
    #             return "è°ƒç”¨å¤±è´¥"
    #
    #     except Exception as e:
    #         log_error(f"LLMè°ƒç”¨å¼‚å¸¸: {e}")
    #         return f"é”™è¯¯: {str(e)}"
    #
    # def _call_gpt_text(self, prompt: str) -> str:
    #     """è°ƒç”¨GPTï¼ˆçº¯æ–‡æœ¬ï¼‰"""
    #     try:
    #         from chat_tool import openapi_client
    #
    #         response = openapi_client.chat.completions.create(
    #             model="Design-4o-mini",
    #             messages=[{"role": "user", "content": prompt}],
    #             max_tokens=2000,
    #             temperature=0.1
    #         )
    #
    #         return response.choices[0].message.content
    #
    #     except Exception as e:
    #         log_error(f"GPTè°ƒç”¨å¼‚å¸¸: {e}")
    #         return f"é”™è¯¯: {str(e)}"


# ç¿»è¯‘æ¨¡å—
# class Translator:
#     def translate(self, text: str, prompt: str, model_type: str, target_lang: str) -> str:
#         """ç¿»è¯‘æ–‡æœ¬"""
#         try:
#             full_prompt = f"{prompt}\n\n{text}"
#
#             if model_type == "æœ¬åœ°LLM Studio":
#                 return self._call_local_llm(full_prompt)
#             else:
#                 return self._call_gpt(full_prompt)
#
#         except Exception as e:
#             return f"é”™è¯¯: {str(e)}"
#
#     def _call_local_llm(self, prompt: str) -> str:
#         """è°ƒç”¨æœ¬åœ°LLM"""
#         try:
#             import requests
#
#             payload = {
#                 "model": "gpt-3.5-turbo",
#                 "messages": [{"role": "user", "content": prompt}],
#                 "max_tokens": 500,
#                 "temperature": 0.3
#             }
#
#             response = requests.post(
#                 "http://localhost:1234/v1/chat/completions",
#                 json=payload,
#                 timeout=60
#             )
#
#             if response.status_code == 200:
#                 result = response.json()
#                 return result['choices'][0]['message']['content'].strip()
#             else:
#                 return "ç¿»è¯‘å¤±è´¥"
#
#         except Exception as e:
#             return f"é”™è¯¯: {str(e)}"
#
#     def _call_gpt(self, prompt: str) -> str:
#         """è°ƒç”¨GPT"""
#         try:
#             from chat_tool import openapi_client
#
#             response = openapi_client.chat.completions.create(
#                 model="Design-4o-mini",
#                 messages=[{"role": "user", "content": prompt}],
#                 max_tokens=500,
#                 temperature=0.3
#             )
#
#             return response.choices[0].message.content.strip()
#
#         except Exception as e:
#             return f"é”™è¯¯: {str(e)}"


# ç®€åŒ–çš„æ•°æ®ç®¡ç†æ¨¡å—
class DatasetManager:
    pass


def create_gradio_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    system = SimpleImageLabelingSystem()

    with gr.Blocks(title="ç®€åŒ–ç‰ˆå›¾åƒæ‰“æ ‡ç³»ç»Ÿ", theme=gr.themes.Soft(), fill_width=True) as interface:
        gr.Markdown("# ğŸ·ï¸ ç®€åŒ–ç‰ˆå›¾åƒæ‰“æ ‡ç³»ç»Ÿ")

        with gr.Tab("ğŸ“ æ•°æ®åŠ è½½"):
            with gr.Row():
                folder_input = gr.Textbox(
                    label="å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„",
                    placeholder="è¾“å…¥åŒ…å«å›¾ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„..."
                )
                scan_btn = gr.Button("æ‰«æå›¾ç‰‡", variant="primary")

            scan_status = gr.Textbox(label="æ‰«æçŠ¶æ€")
            gallery_display = gr.HTML(label="å›¾ç‰‡ä¸æ ‡ç­¾")
            refresh_btn = gr.Button("åˆ·æ–°æ˜¾ç¤º")

            def scan_and_display(folder_path):
                images, message = system.scan_images(folder_path)
                gallery_html = system.create_image_gallery_html()
                return message, gallery_html

            scan_btn.click(
                fn=scan_and_display,
                inputs=[folder_input],
                outputs=[scan_status, gallery_display]
            )

            refresh_btn.click(
                fn=lambda: system.create_image_gallery_html(),
                outputs=[gallery_display]
            )

        with gr.Tab("ğŸ¤– AIæ‰“æ ‡"):
            prompt_input = gr.Textbox(
                label="æ‰“æ ‡æç¤ºè¯",
                value=system.config['labeling_prompt'],
                lines=8
            )

            with gr.Row():
                model_choice = gr.Radio(
                    choices=["LLM Studio", "GPT"],
                    label="é€‰æ‹©æ¨¡å‹",
                    value="LLM Studio"
                )
                delay_slider = gr.Slider(
                    minimum=0.5,
                    maximum=5.0,
                    value=2.0,
                    step=0.5,
                    label="è°ƒç”¨é—´éš”(ç§’)"
                )

            start_labeling_btn = gr.Button("å¼€å§‹AIæ‰“æ ‡", variant="primary")
            labeling_status = gr.Textbox(label="æ‰“æ ‡çŠ¶æ€")

            start_labeling_btn.click(
                fn=lambda p, m, d: system.start_ai_labeling(prompt=p, model_type=m, delay=d),
                inputs=[prompt_input, model_choice, delay_slider],
                outputs=[labeling_status]
            )

        with gr.Tab("ğŸ”„ æ ‡ç­¾å½’ä¸€åŒ–"):
            gr.Markdown("### æ­¥éª¤1: åˆ†æå½’ä¸€åŒ–è§„åˆ™")

            with gr.Row():
                normalize_model = gr.Radio(
                    choices=["æœ¬åœ°LLM Studio", "GPT"],
                    label="é€‰æ‹©æ¨¡å‹",
                    value="GPT"
                )
                analyze_btn = gr.Button("åˆ†æå½’ä¸€åŒ–è§„åˆ™", variant="primary")

            # æ˜¾ç¤ºå½’ä¸€åŒ–è§„åˆ™
            rules_display = gr.HTML(label="å½’ä¸€åŒ–è§„åˆ™", visible=False)

            gr.Markdown("### æ­¥éª¤2: é¢„è§ˆä¿®æ”¹å¯¹æ¯”")
            # æ˜¾ç¤ºä¿®æ”¹å‰åå¯¹æ¯”
            comparison_display = gr.HTML(label="æ ‡ç­¾ä¿®æ”¹å¯¹æ¯”", visible=False)

            gr.Markdown("### æ­¥éª¤3: ç¡®è®¤å¹¶åº”ç”¨ä¿®æ”¹")
            with gr.Row():
                apply_btn = gr.Button("âœ… ç¡®è®¤å¹¶åº”ç”¨ä¿®æ”¹", variant="primary", visible=False)
                cancel_btn = gr.Button("âŒ å–æ¶ˆä¿®æ”¹", variant="secondary", visible=False)

            normalization_status = gr.Textbox(label="æ“ä½œçŠ¶æ€", lines=3)

            def analyze_normalization_rules(model):
                system.config['model_type'] = model
                rules_html, comparison_html = system.analyze_normalization(model)

                # åˆ¤æ–­æ˜¯å¦æœ‰æœ‰æ•ˆçš„åˆ†æç»“æœ
                has_results = bool(
                    system.normalization_analysis and 'normalized_labels' in system.normalization_analysis)

                return (
                    rules_html,
                    comparison_html,
                    gr.update(visible=has_results),  # rules_display
                    gr.update(visible=has_results),  # comparison_display
                    gr.update(visible=has_results),  # apply_btn
                    gr.update(visible=has_results),  # cancel_btn
                    "âœ… åˆ†æå®Œæˆï¼Œè¯·æŸ¥çœ‹è§„åˆ™å’Œå¯¹æ¯”ç»“æœ" if has_results else "âŒ åˆ†æå¤±è´¥æˆ–æ²¡æœ‰éœ€è¦å½’ä¸€åŒ–çš„å†…å®¹"
                )

            def apply_normalization_changes():
                result = system.apply_normalization()
                return (
                    result,
                    gr.update(visible=False),  # rules_display
                    gr.update(visible=False),  # comparison_display
                    gr.update(visible=False),  # apply_btn
                    gr.update(visible=False),  # cancel_btn
                    system.create_image_gallery_html()  # æ›´æ–°å›¾ç‰‡æ˜¾ç¤º
                )

            def cancel_normalization_changes():
                result = system.cancel_normalization()
                return (
                    result,
                    gr.update(visible=False),  # rules_display
                    gr.update(visible=False),  # comparison_display
                    gr.update(visible=False),  # apply_btn
                    gr.update(visible=False),  # cancel_btn
                )

            analyze_btn.click(
                fn=analyze_normalization_rules,
                inputs=[normalize_model],
                outputs=[
                    rules_display,
                    comparison_display,
                    rules_display,
                    comparison_display,
                    apply_btn,
                    cancel_btn,
                    normalization_status
                ]
            )

            apply_btn.click(
                fn=apply_normalization_changes,
                outputs=[
                    normalization_status,
                    rules_display,
                    comparison_display,
                    apply_btn,
                    cancel_btn,
                    gallery_display  # æ›´æ–°ä¸»é¡µé¢çš„å›¾ç‰‡æ˜¾ç¤º
                ]
            )

            cancel_btn.click(
                fn=cancel_normalization_changes,
                outputs=[
                    normalization_status,
                    rules_display,
                    comparison_display,
                    apply_btn,
                    cancel_btn
                ]
            )

        with gr.Tab("ğŸŒ æ ‡ç­¾ç¿»è¯‘"):
            translation_prompt = gr.Textbox(
                label="ç¿»è¯‘æç¤ºè¯",
                value=system.config['translation_prompt'],
                lines=5
            )

            with gr.Row():
                trans_model = gr.Radio(
                    choices=["LLM_Studio", "GPT"],
                    label="é€‰æ‹©æ¨¡å‹",
                    value="GPT"
                )
                target_lang = gr.Textbox(
                    label="ç›®æ ‡è¯­è¨€",
                    value="è‹±æ–‡"
                )

            translate_btn = gr.Button("å¼€å§‹ç¿»è¯‘", variant="primary")
            translation_status = gr.Textbox(label="ç¿»è¯‘çŠ¶æ€")

            translate_btn.click(
                fn=system.translate_labels,
                inputs=[translation_prompt, trans_model, target_lang],
                outputs=[translation_status]
            )

        with gr.Tab("ğŸ’¾ æ•°æ®ç®¡ç†"):
            export_format = gr.Radio(
                choices=["json", "csv"],
                label="ä¿å­˜æ ¼å¼",
                value="json"
            )

            save_btn = gr.Button("ä¿å­˜æ•°æ®é›†", variant="primary")
            save_status = gr.Textbox(label="ä¿å­˜çŠ¶æ€")

            save_btn.click(
                fn=system.save_dataset,
                inputs=[export_format],
                outputs=[save_status]
            )

    return interface


def main():
    """ä¸»å‡½æ•°"""
    interface = create_gradio_interface()
    interface.launch(
        server_name="127.0.0.1",
        server_port=7860,
        share=False
    )


if __name__ == "__main__":
    main()
