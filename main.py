#!/usr/bin/env python3
"""
ç²¾ç®€ç‰ˆå›¾åƒæ‰“æ ‡ç³»ç»Ÿ
"""

import gradio as gr
import os
import json
import time
from pathlib import Path
from typing import Dict, List, Tuple
import pandas as pd
from datetime import datetime
import base64
from PIL import Image
import io


# ç®€å•çš„æ—¥å¿—è®°å½•
def log_info(message):
    print(f"[INFO] {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {message}")


def log_error(message):
    print(f"[ERROR] {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {message}")


class SimpleImageLabelingSystem:
    def __init__(self):
        # æ ¸å¿ƒæ•°æ®
        self.current_folder = ""
        self.images = []
        self.labels = {}

        # AIæ‰“æ ‡æ¨¡å—
        self.ai_labeler = AILabeler()
        self.tag_normalizer = TagNormalizer()
        self.translator = Translator()
        self.dataset_manager = DatasetManager()

        # é…ç½®
        self.config = {
            'labeling_prompt': self._default_labeling_prompt(),
            'translation_prompt': self._default_translation_prompt(),
            'model_type': 'GPT',
            'batch_size': 1,
            'delay_between_calls': 2.0
        }

        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        self.supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp'}

    def _default_labeling_prompt(self) -> str:
        """é»˜è®¤çš„æ‰“æ ‡æç¤ºè¯"""
        return """ä½ æ˜¯ä¸€åå›¾åƒç†è§£ä¸“å®¶ï¼Œè¯·æ ¹æ®ä»¥ä¸‹å›¾ç‰‡å†…å®¹ï¼Œç”Ÿæˆè‡ªç„¶æµç•…ã€å…·ä½“æ¸…æ™°çš„å›¾åƒæè¿°ã€‚è¦æ±‚å¦‚ä¸‹ï¼š
1. ä½¿ç”¨ç®€æ´å‡†ç¡®çš„ä¸­æ–‡å¥å­ï¼›
2. æè¿°åº”åŒ…æ‹¬å›¾åƒä¸­çš„ä¸»ä½“ã€åŠ¨ä½œã€ä½ç½®æˆ–èƒŒæ™¯ç¯å¢ƒï¼›
3. é¿å…ä½¿ç”¨"å›¾ä¸­"ã€"è¿™æ˜¯ä¸€å¼ å›¾ç‰‡"ç­‰å†—ä½™æªè¾ï¼›
4. è¯­è¨€é£æ ¼è‡ªç„¶ã€å…·è±¡ï¼Œä¸ä½¿ç”¨æŠ½è±¡å½¢å®¹è¯æˆ–ä¸»è§‚æ„Ÿå—ï¼›
5. æè¿°çš„ç»“æ„ä¸º[ä¸»ä½“] + [å¤–è§‚/æœè£…] + [åŠ¨ä½œ/å§¿åŠ¿] + [èƒŒæ™¯/ç¯å¢ƒ] + [æ°›å›´/ç¯å…‰ï¼ˆå¯é€‰ï¼‰]
ç¤ºä¾‹ï¼š
ä¸»ä½“ï¼šxxx
å¤–è§‚/æœè£…ï¼šxxx
åŠ¨ä½œ/å§¿åŠ¿ï¼šxxx
èƒŒæ™¯/ç¯å¢ƒï¼šxxx
æ°›å›´/ç¯å…‰ï¼šxxx


ç°åœ¨è¯·æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼š"""

    def _default_translation_prompt(self) -> str:
        """é»˜è®¤çš„ç¿»è¯‘æç¤ºè¯"""
        return """è¯·å°†ä»¥ä¸‹ä¸­æ–‡æè¿°ç¿»è¯‘æˆè‹±æ–‡ï¼Œä¿æŒåŸæ„ä¸å˜ï¼Œè¦æ±‚ï¼š
1. ç¿»è¯‘è¦å‡†ç¡®ã€è‡ªç„¶ã€æµç•…
2. ä¿æŒåŸæ–‡çš„æè¿°é¡ºåºå’Œé‡ç‚¹
3. ä½¿ç”¨é€‚åˆAIç»˜ç”»çš„æè¿°é£æ ¼
4. ç›´æ¥è¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸è¦åŠ ä»»ä½•é¢å¤–è¯´æ˜

ä¸­æ–‡æè¿°ï¼š"""

    def scan_images(self, folder_path: str) -> Tuple[List[str], str]:
        """æ‰«ææ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡"""
        try:
            if not os.path.exists(folder_path):
                return [], "æ–‡ä»¶å¤¹ä¸å­˜åœ¨"

            self.current_folder = folder_path
            self.images = []

            for file in os.listdir(folder_path):
                if Path(file).suffix.lower() in self.supported_formats:
                    img_path = os.path.join(folder_path, file)
                    self.images.append(img_path)

            self.images.sort()
            self.load_existing_labels()

            message = f"æ‰¾åˆ° {len(self.images)} å¼ å›¾ç‰‡"
            log_info(message)

            return self.images, message

        except Exception as e:
            error_msg = f"æ‰«ææ–‡ä»¶å¤¹å‡ºé”™: {str(e)}"
            log_error(error_msg)
            return [], error_msg

    def load_existing_labels(self):
        """åŠ è½½å·²æœ‰çš„æ ‡ç­¾æ–‡ä»¶"""
        self.labels = {}

        for img_path in self.images:
            txt_path = os.path.splitext(img_path)[0] + '.txt'
            label_text = ""

            if os.path.exists(txt_path):
                try:
                    with open(txt_path, 'r', encoding='utf-8') as f:
                        label_text = f.read().strip()
                except Exception as e:
                    log_error(f"è¯»å–æ ‡ç­¾æ–‡ä»¶å¤±è´¥ {txt_path}: {e}")

            self.labels[img_path] = label_text

    def create_image_gallery_html(self) -> str:
        """åˆ›å»ºå›¾ç‰‡å±•ç¤ºHTML"""
        if not self.images:
            return "<p>æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡</p>"

        html_parts = ["<div style='display: flex; flex-wrap: wrap; gap: 10px; padding: 10px;'>"]

        for i, img_path in enumerate(self.images):
            img_name = os.path.basename(img_path)
            current_label = self.labels.get(img_path, "")

            # è¯»å–å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64
            try:
                with Image.open(img_path) as img:
                    # åˆ›å»ºç¼©ç•¥å›¾
                    img.thumbnail((300, 300), Image.Resampling.LANCZOS)
                    buffer = io.BytesIO()
                    img.save(buffer, format='JPEG', quality=85)
                    img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
                    img_src = f"data:image/jpeg;base64,{img_base64}"
            except:
                img_src = ""

            # åˆ›å»ºå›¾ç‰‡å¡ç‰‡
            img_container = f"""
            <div style='
                width: 300px;
                border: 1px solid #ddd;
                padding: 10px;
                border-radius: 5px;
                background: white;
            '>
                <div style='text-align: center; margin-bottom: 10px;'>
                    <img src='{img_src}' style='max-width: 100%; max-height: 200px;' alt='{img_name}'/>
                </div>
                <div style='font-weight: bold; margin-bottom: 5px; word-break: break-all;'>
                    {img_name}
                </div>
                <div>
                    <textarea id='label_{i}' 
                              style='width: 100%; height: 80px; resize: vertical;' 
                              placeholder='æ ‡ç­¾å†…å®¹...'
                              readonly>{current_label}</textarea>
                </div>
                <div style='text-align: right; margin-top: 5px; color: {"green" if current_label else "orange"}'>
                    {'âœ“ å·²æ ‡æ³¨' if current_label else 'â—‹ æœªæ ‡æ³¨'}
                </div>
            </div>
            """
            html_parts.append(img_container)

        html_parts.append("</div>")

        # ç»Ÿè®¡ä¿¡æ¯
        labeled_count = len([l for l in self.labels.values() if l.strip()])
        stats_html = f"""
        <div style='background: #f0f0f0; padding: 10px; margin-bottom: 10px; border-radius: 5px;'>
            <h3>æ•°æ®é›†ç»Ÿè®¡</h3>
            <p>æ€»æ•°: {len(self.images)} | å·²æ ‡æ³¨: {labeled_count} | æœªæ ‡æ³¨: {len(self.images) - labeled_count}</p>
        </div>
        """

        return stats_html + ''.join(html_parts)

    def start_ai_labeling(self, prompt: str, model_type: str, batch_size: int, delay: float) -> str:
        """å¼€å§‹AIæ‰“æ ‡"""
        try:
            # åªæ ‡æ³¨æœªæ ‡æ³¨çš„å›¾ç‰‡
            unlabeled_images = [img for img in self.images if not self.labels.get(img, "").strip()]

            if not unlabeled_images:
                return "æ‰€æœ‰å›¾ç‰‡éƒ½å·²æ ‡æ³¨"

            success_count = 0

            # é€ä¸ªå¤„ç†å›¾ç‰‡
            for i, img_path in enumerate(unlabeled_images):
                try:
                    # è°ƒç”¨AIè¿›è¡Œæ ‡æ³¨
                    if model_type == "æœ¬åœ°LLM Studio":
                        label_text = self.ai_labeler.call_local_llm(img_path, prompt)
                    else:  # GPT
                        label_text = self.ai_labeler.call_gpt(img_path, prompt)

                    if label_text and not label_text.startswith("é”™è¯¯"):
                        self.labels[img_path] = label_text
                        success_count += 1

                        # ä¿å­˜åˆ°æ–‡ä»¶
                        txt_path = os.path.splitext(img_path)[0] + '.txt'
                        with open(txt_path, 'w', encoding='utf-8') as f:
                            f.write(label_text)

                    log_info(f"å®Œæˆ {i + 1}/{len(unlabeled_images)}: {os.path.basename(img_path)}")

                    # å»¶è¿Ÿé¿å…APIé™åˆ¶
                    if i < len(unlabeled_images) - 1:
                        time.sleep(delay)

                except Exception as e:
                    log_error(f"å¤„ç†å›¾ç‰‡å¤±è´¥ {img_path}: {e}")
                    continue

            return f"AIæ ‡æ³¨å®Œæˆï¼ŒæˆåŠŸæ ‡æ³¨ {success_count}/{len(unlabeled_images)} å¼ å›¾ç‰‡"

        except Exception as e:
            error_msg = f"AIæ ‡æ³¨å¤±è´¥: {str(e)}"
            log_error(error_msg)
            return error_msg

    def normalize_tags(self) -> str:
        """æ ‡ç­¾å½’ä¸€åŒ–"""
        try:
            # æ”¶é›†æ‰€æœ‰æ ‡ç­¾
            all_labels = {}
            for img_path, label_text in self.labels.items():
                if label_text and label_text.strip():
                    all_labels[os.path.basename(img_path)] = label_text

            if not all_labels:
                return "æ²¡æœ‰æ ‡ç­¾éœ€è¦å½’ä¸€åŒ–"

            # è°ƒç”¨AIåˆ†æéœ€è¦å½’ä¸€åŒ–çš„æ ‡ç­¾
            normalization_result = self.tag_normalizer.analyze_normalization(all_labels, self.config['model_type'])

            if isinstance(normalization_result, dict) and 'normalized_labels' in normalization_result:
                # åº”ç”¨å½’ä¸€åŒ–ç»“æœ
                changes_count = 0
                for img_name, new_label in normalization_result['normalized_labels'].items():
                    for img_path in self.images:
                        if os.path.basename(img_path) == img_name:
                            if self.labels[img_path] != new_label:
                                self.labels[img_path] = new_label
                                changes_count += 1

                                # ä¿å­˜åˆ°æ–‡ä»¶
                                txt_path = os.path.splitext(img_path)[0] + '.txt'
                                with open(txt_path, 'w', encoding='utf-8') as f:
                                    f.write(new_label)
                            break

                return f"æ ‡ç­¾å½’ä¸€åŒ–å®Œæˆï¼Œä¿®æ”¹äº† {changes_count} ä¸ªæ ‡ç­¾"
            else:
                return "æ ‡ç­¾å½’ä¸€åŒ–åˆ†æå¤±è´¥"

        except Exception as e:
            error_msg = f"æ ‡ç­¾å½’ä¸€åŒ–å¤±è´¥: {str(e)}"
            log_error(error_msg)
            return error_msg

    def translate_labels(self, prompt: str, model_type: str, target_lang: str = "è‹±æ–‡") -> str:
        """ç¿»è¯‘æ ‡ç­¾"""
        try:
            # æ”¶é›†éœ€è¦ç¿»è¯‘çš„æ ‡ç­¾
            labels_to_translate = {}
            for img_path, label_text in self.labels.items():
                if label_text and label_text.strip():
                    labels_to_translate[img_path] = label_text

            if not labels_to_translate:
                return "æ²¡æœ‰æ ‡ç­¾éœ€è¦ç¿»è¯‘"

            success_count = 0

            # é€ä¸ªç¿»è¯‘
            for img_path, original_label in labels_to_translate.items():
                try:
                    # è°ƒç”¨ç¿»è¯‘
                    translated = self.translator.translate(original_label, prompt, model_type, target_lang)

                    if translated and not translated.startswith("é”™è¯¯"):
                        # ä¿å­˜ç¿»è¯‘ç»“æœåˆ°æ–°æ–‡ä»¶
                        base_path = os.path.splitext(img_path)[0]
                        translated_file = f"{base_path}_translated.txt"
                        with open(translated_file, 'w', encoding='utf-8') as f:
                            f.write(translated)
                        success_count += 1

                        log_info(f"ç¿»è¯‘å®Œæˆ: {os.path.basename(img_path)}")

                    # çŸ­æš‚å»¶è¿Ÿ
                    time.sleep(0.5)

                except Exception as e:
                    log_error(f"ç¿»è¯‘å¤±è´¥ {img_path}: {e}")
                    continue

            return f"ç¿»è¯‘å®Œæˆï¼ŒæˆåŠŸç¿»è¯‘ {success_count}/{len(labels_to_translate)} ä¸ªæ ‡ç­¾"

        except Exception as e:
            error_msg = f"ç¿»è¯‘å¤±è´¥: {str(e)}"
            log_error(error_msg)
            return error_msg

    def save_dataset(self, format_type: str) -> str:
        """ä¿å­˜æ•°æ®é›†"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

            if format_type == "json":
                # ä¿å­˜ä¸ºJSONæ ¼å¼
                output_file = os.path.join(self.current_folder, f"dataset_{timestamp}.json")
                dataset = {
                    'images': [],
                    'created': timestamp
                }

                for img_path, label in self.labels.items():
                    dataset['images'].append({
                        'filename': os.path.basename(img_path),
                        'path': img_path,
                        'label': label
                    })

                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(dataset, f, ensure_ascii=False, indent=2)

                return f"æ•°æ®é›†å·²ä¿å­˜åˆ°: {output_file}"

            elif format_type == "csv":
                # ä¿å­˜ä¸ºCSVæ ¼å¼
                output_file = os.path.join(self.current_folder, f"dataset_{timestamp}.csv")
                df = pd.DataFrame([
                    {'filename': os.path.basename(path), 'label': label}
                    for path, label in self.labels.items()
                ])
                df.to_csv(output_file, index=False, encoding='utf-8')

                return f"æ•°æ®é›†å·²ä¿å­˜åˆ°: {output_file}"

            else:
                return "ä¸æ”¯æŒçš„æ ¼å¼"

        except Exception as e:
            return f"ä¿å­˜å¤±è´¥: {str(e)}"


# AIæ ‡æ³¨æ¨¡å—
class AILabeler:
    def __init__(self):
        self.llm_studio_url = "http://localhost:1234/v1"

    def encode_image_to_base64(self, image_path: str) -> str:
        """å°†å›¾ç‰‡ç¼–ç ä¸ºbase64"""
        try:
            with Image.open(image_path) as img:
                # è°ƒæ•´å¤§å°
                max_size = (1024, 1024)
                img.thumbnail(max_size, Image.Resampling.LANCZOS)

                buffer = io.BytesIO()
                img.save(buffer, format='JPEG', quality=85)
                img_str = base64.b64encode(buffer.getvalue()).decode()
                return img_str
        except Exception as e:
            log_error(f"å›¾ç‰‡ç¼–ç å¤±è´¥ {image_path}: {e}")
            return ""

    def call_gpt(self, image_path: str, prompt: str) -> str:
        """è°ƒç”¨GPTï¼ˆéœ€è¦æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰"""
        try:
            # å¯¼å…¥GPTè°ƒç”¨æ¨¡å—
            from use_gpt import get_completion, encode_image_to_base64

            img_base64 = encode_image_to_base64(image_path)
            result = get_completion(control="customize", prompt=prompt, content=img_base64)

            return result if result else "GPTè°ƒç”¨å¤±è´¥"

        except Exception as e:
            log_error(f"GPTè°ƒç”¨é”™è¯¯: {e}")
            return f"é”™è¯¯: {str(e)}"

    def call_local_llm(self, image_path: str, prompt: str) -> str:
        """è°ƒç”¨æœ¬åœ°LLM Studio"""
        try:
            import requests

            base64_image = self.encode_image_to_base64(image_path)
            if not base64_image:
                return "å›¾ç‰‡ç¼–ç å¤±è´¥"

            payload = {
                "model": "gpt-4-vision-preview",
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                "max_tokens": 300,
                "temperature": 0.3
            }

            response = requests.post(
                f"{self.llm_studio_url}/chat/completions",
                json=payload,
                timeout=60
            )

            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content'].strip()
            else:
                return f"æœ¬åœ°LLMè°ƒç”¨å¤±è´¥: {response.status_code}"

        except Exception as e:
            log_error(f"æœ¬åœ°LLMè°ƒç”¨å¤±è´¥: {e}")
            return f"é”™è¯¯: {str(e)}"


# æ ‡ç­¾å½’ä¸€åŒ–æ¨¡å—
class TagNormalizer:
    def analyze_normalization(self, labels_dict: Dict[str, str], model_type: str) -> dict:
        """åˆ†æéœ€è¦å½’ä¸€åŒ–çš„æ ‡ç­¾"""
        try:
            # æ„å»ºå‘é€ç»™AIçš„å†…å®¹
            prompt = """è¯·åˆ†æä»¥ä¸‹å›¾åƒæ ‡ç­¾ï¼Œæ‰¾å‡ºéœ€è¦å½’ä¸€åŒ–çš„å†…å®¹ã€‚
è¯·è¯†åˆ«ï¼š
1. ç›¸ä¼¼æˆ–é‡å¤çš„æè¿°
2. å¯ä»¥ç»Ÿä¸€çš„è¡¨è¾¾æ–¹å¼
3. éœ€è¦ä¿®æ­£çš„æ ¼å¼é—®é¢˜

æ ‡ç­¾åˆ—è¡¨ï¼š
"""

            for img_name, label in labels_dict.items():
                prompt += f"\n{img_name}: {label}"

            prompt += """

è¯·è¿”å›JSONæ ¼å¼çš„å½’ä¸€åŒ–å»ºè®®ï¼š
{
    "suggestions": [
        {"åŸå§‹": "xxx", "å»ºè®®": "yyy", "åŸå› ": "zzz"}
    ],
    "normalized_labels": {
        "å›¾ç‰‡å": "å½’ä¸€åŒ–åçš„æ ‡ç­¾"
    }
}"""

            # è°ƒç”¨AI
            if model_type == "æœ¬åœ°LLM Studio":
                result = self._call_local_llm_text(prompt)
            else:
                result = self._call_gpt_text(prompt)

            # è§£æç»“æœ
            try:
                # æå–JSONéƒ¨åˆ†
                json_start = result.find('{')
                json_end = result.rfind('}') + 1
                if json_start != -1 and json_end > json_start:
                    json_str = result[json_start:json_end]
                    return json.loads(json_str)
            except:
                log_error("è§£æå½’ä¸€åŒ–ç»“æœå¤±è´¥")

            return {"error": "è§£æå¤±è´¥"}

        except Exception as e:
            log_error(f"å½’ä¸€åŒ–åˆ†æå¤±è´¥: {e}")
            return {"error": str(e)}

    def _call_local_llm_text(self, prompt: str) -> str:
        """è°ƒç”¨æœ¬åœ°LLMï¼ˆçº¯æ–‡æœ¬ï¼‰"""
        try:
            import requests

            payload = {
                "model": "gpt-3.5-turbo",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 1000,
                "temperature": 0.1
            }

            response = requests.post(
                "http://localhost:1234/v1/chat/completions",
                json=payload,
                timeout=60
            )

            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content']
            else:
                return "è°ƒç”¨å¤±è´¥"

        except Exception as e:
            return f"é”™è¯¯: {str(e)}"

    def _call_gpt_text(self, prompt: str) -> str:
        """è°ƒç”¨GPTï¼ˆçº¯æ–‡æœ¬ï¼‰"""
        try:
            from use_gpt import openapi_client

            response = openapi_client.chat.completions.create(
                model="Design-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1000,
                temperature=0.1
            )

            return response.choices[0].message.content

        except Exception as e:
            return f"é”™è¯¯: {str(e)}"


# ç¿»è¯‘æ¨¡å—
class Translator:
    def translate(self, text: str, prompt: str, model_type: str, target_lang: str) -> str:
        """ç¿»è¯‘æ–‡æœ¬"""
        try:
            full_prompt = f"{prompt}\n\n{text}"

            if model_type == "æœ¬åœ°LLM Studio":
                return self._call_local_llm(full_prompt)
            else:
                return self._call_gpt(full_prompt)

        except Exception as e:
            return f"é”™è¯¯: {str(e)}"

    def _call_local_llm(self, prompt: str) -> str:
        """è°ƒç”¨æœ¬åœ°LLM"""
        try:
            import requests

            payload = {
                "model": "gpt-3.5-turbo",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 500,
                "temperature": 0.3
            }

            response = requests.post(
                "http://localhost:1234/v1/chat/completions",
                json=payload,
                timeout=60
            )

            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content'].strip()
            else:
                return "ç¿»è¯‘å¤±è´¥"

        except Exception as e:
            return f"é”™è¯¯: {str(e)}"

    def _call_gpt(self, prompt: str) -> str:
        """è°ƒç”¨GPT"""
        try:
            from use_gpt import openapi_client

            response = openapi_client.chat.completions.create(
                model="Design-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=500,
                temperature=0.3
            )

            return response.choices[0].message.content.strip()

        except Exception as e:
            return f"é”™è¯¯: {str(e)}"


# ç®€åŒ–çš„æ•°æ®ç®¡ç†æ¨¡å—
class DatasetManager:
    pass


def create_gradio_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    system = SimpleImageLabelingSystem()

    with gr.Blocks(title="ç®€åŒ–ç‰ˆå›¾åƒæ‰“æ ‡ç³»ç»Ÿ", theme=gr.themes.Soft(),fill_width=True) as interface:
        gr.Markdown("# ğŸ·ï¸ ç®€åŒ–ç‰ˆå›¾åƒæ‰“æ ‡ç³»ç»Ÿ")

        with gr.Tab("ğŸ“ æ•°æ®åŠ è½½"):
            with gr.Row():
                folder_input = gr.Textbox(
                    label="å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„",
                    placeholder="è¾“å…¥åŒ…å«å›¾ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„..."
                )
                scan_btn = gr.Button("æ‰«æå›¾ç‰‡", variant="primary")

            scan_status = gr.Textbox(label="æ‰«æçŠ¶æ€")
            gallery_display = gr.HTML(label="å›¾ç‰‡ä¸æ ‡ç­¾")
            refresh_btn = gr.Button("åˆ·æ–°æ˜¾ç¤º")

            def scan_and_display(folder_path):
                images, message = system.scan_images(folder_path)
                gallery_html = system.create_image_gallery_html()
                return message, gallery_html

            scan_btn.click(
                fn=scan_and_display,
                inputs=[folder_input],
                outputs=[scan_status, gallery_display]
            )

            refresh_btn.click(
                fn=lambda: system.create_image_gallery_html(),
                outputs=[gallery_display]
            )

        with gr.Tab("ğŸ¤– AIæ‰“æ ‡"):
            prompt_input = gr.Textbox(
                label="æ‰“æ ‡æç¤ºè¯",
                value=system.config['labeling_prompt'],
                lines=8
            )

            with gr.Row():
                model_choice = gr.Radio(
                    choices=["æœ¬åœ°LLM Studio", "GPT"],
                    label="é€‰æ‹©æ¨¡å‹",
                    value="GPT"
                )
                delay_slider = gr.Slider(
                    minimum=0.5,
                    maximum=5.0,
                    value=2.0,
                    step=0.5,
                    label="è°ƒç”¨é—´éš”(ç§’)"
                )

            start_labeling_btn = gr.Button("å¼€å§‹AIæ‰“æ ‡", variant="primary")
            labeling_status = gr.Textbox(label="æ‰“æ ‡çŠ¶æ€")

            start_labeling_btn.click(
                fn=lambda p, m, d: system.start_ai_labeling(p, m, 1, d),
                inputs=[prompt_input, model_choice, delay_slider],
                outputs=[labeling_status]
            )

        with gr.Tab("ğŸ”„ æ ‡ç­¾å½’ä¸€åŒ–"):
            gr.Markdown("### åˆ†æå¹¶å½’ä¸€åŒ–æ ‡ç­¾")

            normalize_model = gr.Radio(
                choices=["æœ¬åœ°LLM Studio", "GPT"],
                label="é€‰æ‹©æ¨¡å‹",
                value="GPT"
            )

            normalize_btn = gr.Button("æ‰§è¡Œå½’ä¸€åŒ–åˆ†æ", variant="primary")
            normalization_status = gr.Textbox(label="å½’ä¸€åŒ–çŠ¶æ€", lines=5)

            def run_normalization(model):
                system.config['model_type'] = model
                return system.normalize_tags()

            normalize_btn.click(
                fn=run_normalization,
                inputs=[normalize_model],
                outputs=[normalization_status]
            )

        with gr.Tab("ğŸŒ æ ‡ç­¾ç¿»è¯‘"):
            translation_prompt = gr.Textbox(
                label="ç¿»è¯‘æç¤ºè¯",
                value=system.config['translation_prompt'],
                lines=5
            )

            with gr.Row():
                trans_model = gr.Radio(
                    choices=["æœ¬åœ°LLM Studio", "GPT"],
                    label="é€‰æ‹©æ¨¡å‹",
                    value="GPT"
                )
                target_lang = gr.Textbox(
                    label="ç›®æ ‡è¯­è¨€",
                    value="è‹±æ–‡"
                )

            translate_btn = gr.Button("å¼€å§‹ç¿»è¯‘", variant="primary")
            translation_status = gr.Textbox(label="ç¿»è¯‘çŠ¶æ€")

            translate_btn.click(
                fn=system.translate_labels,
                inputs=[translation_prompt, trans_model, target_lang],
                outputs=[translation_status]
            )

        with gr.Tab("ğŸ’¾ æ•°æ®ç®¡ç†"):
            export_format = gr.Radio(
                choices=["json", "csv"],
                label="ä¿å­˜æ ¼å¼",
                value="json"
            )

            save_btn = gr.Button("ä¿å­˜æ•°æ®é›†", variant="primary")
            save_status = gr.Textbox(label="ä¿å­˜çŠ¶æ€")

            save_btn.click(
                fn=system.save_dataset,
                inputs=[export_format],
                outputs=[save_status]
            )

    return interface


def main():
    """ä¸»å‡½æ•°"""
    interface = create_gradio_interface()
    interface.launch(
        server_name="127.0.0.1",
        server_port=7860,
        share=False
    )


if __name__ == "__main__":
    main()
