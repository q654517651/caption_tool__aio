# è®­ç»ƒæ–‡ä»¶ç”Ÿæˆç¤ºä¾‹

TagTracker ç°åœ¨ä¼šä¸ºæ¯ä¸ªè®­ç»ƒä»»åŠ¡ç”Ÿæˆå®Œæ•´çš„è®­ç»ƒæ–‡ä»¶ï¼Œæ—¢å¯ä»¥é€šè¿‡ç•Œé¢æ‰§è¡Œï¼Œä¹Ÿå¯ä»¥æ‰‹åŠ¨è¿è¡Œã€‚

## ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶ç»“æ„

æ¯ä¸ªè®­ç»ƒä»»åŠ¡ä¼šåœ¨ `workspace/trainings/{task_id}/` ç›®å½•ä¸‹ç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

```
workspace/trainings/a1b2c3d4-e5f6-7890-abcd-ef1234567890/
â”œâ”€â”€ datasets.toml          # Musubi æ•°æ®é›†é…ç½®æ–‡ä»¶
â”œâ”€â”€ train.bat             # Windows è®­ç»ƒè„šæœ¬
â”œâ”€â”€ train.sh              # Linux/Mac è®­ç»ƒè„šæœ¬  
â”œâ”€â”€ config.json           # å®Œæ•´çš„è®­ç»ƒå‚æ•°è®°å½•
â”œâ”€â”€ cache/                # è®­ç»ƒç¼“å­˜ç›®å½•
â””â”€â”€ logs/                 # è®­ç»ƒæ—¥å¿—ç›®å½•
    â””â”€â”€ training.log      # è®­ç»ƒè¾“å‡ºæ—¥å¿—
```

## ğŸ“„ æ–‡ä»¶å†…å®¹ç¤ºä¾‹

### datasets.toml
```toml
[general]
resolution = [1024, 1024]
batch_size = 2
enable_bucket = true
bucket_no_upscale = false
bucket_resolution_steps = 64
min_bucket_reso = 256
max_bucket_reso = 1536

[[datasets]]
image_directory = "E:/Program/workspace/datasets/f118d5d7/original"
cache_directory = "E:/Program/workspace/trainings/a1b2c3d4/cache"
caption_extension = ".txt"
num_repeats = 1
```

### train.bat (Windows)
```batch
@echo off
echo ===== TagTracker Musubi è®­ç»ƒè„šæœ¬ =====
echo ä»»åŠ¡åç§°: Qwen-Image-LoRA-Test
echo å¼€å§‹æ—¶é—´: %date% %time%
echo =====================================

cd /d "E:\Program\programlearn\tagtragger"

accelerate launch "third_party/musubi-tuner/src/musubi_tuner/qwen_image_train_network.py" ^
--dataset_config "workspace/trainings/a1b2c3d4/datasets.toml" ^
--output_dir "workspace/models/Qwen-Image-LoRA-Test" ^
--output_name "Qwen-Image-LoRA-Test" ^
--network_module networks.lora ^
--network_dim 32 ^
--network_alpha 16 ^
--max_train_epochs 16 ^
--learning_rate 1e-4 ^
--optimizer_type adamw8bit ^
--lr_scheduler cosine ^
--mixed_precision bf16 ^
--save_every_n_epochs 1 ^
--seed 42 ^
2>&1 | tee "workspace/trainings/a1b2c3d4/logs/training.log"

echo =====================================
echo è®­ç»ƒå®Œæˆæ—¶é—´: %date% %time%
echo =====================================
pause
```

### train.sh (Linux/Mac)
```bash
#!/bin/bash
echo "===== TagTracker Musubi è®­ç»ƒè„šæœ¬ ====="
echo "ä»»åŠ¡åç§°: Qwen-Image-LoRA-Test"
echo "å¼€å§‹æ—¶é—´: $(date)"
echo "====================================="

cd "E:/Program/programlearn/tagtragger"

accelerate launch "third_party/musubi-tuner/src/musubi_tuner/qwen_image_train_network.py" \
--dataset_config "workspace/trainings/a1b2c3d4/datasets.toml" \
--output_dir "workspace/models/Qwen-Image-LoRA-Test" \
--output_name "Qwen-Image-LoRA-Test" \
--network_module networks.lora \
--network_dim 32 \
--network_alpha 16 \
--max_train_epochs 16 \
--learning_rate 1e-4 \
--optimizer_type adamw8bit \
--lr_scheduler cosine \
--mixed_precision bf16 \
--save_every_n_epochs 1 \
--seed 42 \
2>&1 | tee "workspace/trainings/a1b2c3d4/logs/training.log"

echo "====================================="
echo "è®­ç»ƒå®Œæˆæ—¶é—´: $(date)"
echo "====================================="
```

### config.json
```json
{
  "backend": "musubi.qwen_image",
  "name": "Qwen-Image-LoRA-Test",
  "dataset_id": "f118d5d7-8385-4a14-aebb-a2cccfb6aeae",
  "dataset_size": 20,
  "task_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "repeats": 1,
  "epochs": 16,
  "batch_size": 2,
  "grad_accum": 1,
  "resolution": "1024,1024",
  "base_model": "",
  "optimizer": "adamw8bit",
  "lr": 1e-4,
  "scheduler": "cosine",
  "warmup_ratio": 0.0,
  "weight_decay": 0.0,
  "precision": "bf16",
  "sample_prompt": "",
  "sample_every_n_steps": 200,
  "gpu_index": 0,
  "created_at": "2024-08-12 15:30:45",
  "platform": "Windows"
}
```

## ğŸ¯ ä½¿ç”¨æ–¹å¼

### 1. é€šè¿‡ TagTracker ç•Œé¢
- æ­£å¸¸åˆ›å»ºè®­ç»ƒä»»åŠ¡
- æ–‡ä»¶ä¼šè‡ªåŠ¨ç”Ÿæˆå¹¶ä¿å­˜
- è®­ç»ƒé€šè¿‡ç•Œé¢ç®¡ç†å’Œç›‘æ§

### 2. æ‰‹åŠ¨æ‰§è¡Œè®­ç»ƒè„šæœ¬
```bash
# Windows
cd /d "E:\Program\programlearn\tagtragger"
workspace\trainings\a1b2c3d4\train.bat

# Linux/Mac
cd "/path/to/tagtragger"
bash workspace/trainings/a1b2c3d4/train.sh
```

### 3. è‡ªå®šä¹‰ä¿®æ”¹
- ç¼–è¾‘ `datasets.toml` è°ƒæ•´æ•°æ®é›†é…ç½®
- ç¼–è¾‘ `train.bat/train.sh` ä¿®æ”¹è®­ç»ƒå‚æ•°
- é‡æ–°æ‰§è¡Œè„šæœ¬

## ğŸ’¡ ä¼˜åŠ¿ç‰¹ç‚¹

### âœ… å®Œæ•´çš„å‚æ•°è®°å½•
- æ‰€æœ‰è®­ç»ƒå‚æ•°éƒ½ä¿å­˜åœ¨æ–‡ä»¶ä¸­
- æ–¹ä¾¿åç»­å¤ç°å’Œè°ƒè¯•
- å¯ä»¥ä½œä¸ºè®­ç»ƒå†å²çš„å¤‡ä»½

### âœ… ç‹¬ç«‹çš„ç¼“å­˜ç®¡ç†
- æ¯ä¸ªè®­ç»ƒä»»åŠ¡æœ‰ç‹¬ç«‹çš„ç¼“å­˜ç›®å½•
- é¿å…ä¸åŒè®­ç»ƒä¹‹é—´çš„ç¼“å­˜å†²çª
- ä¾¿äºæ¸…ç†å’Œç®¡ç†å­˜å‚¨ç©ºé—´

### âœ… å¹³å°å…¼å®¹æ€§
- åŒæ—¶ç”Ÿæˆ Windows å’Œ Linux/Mac è„šæœ¬
- è‡ªåŠ¨æ£€æµ‹å¹³å°é€‰æ‹©åˆé€‚çš„æ‰§è¡Œæ–¹å¼
- ç¡®ä¿è·¨å¹³å°çš„ä¸€è‡´æ€§

### âœ… è°ƒè¯•å‹å¥½
- ç”Ÿæˆçš„è„šæœ¬äººç±»å¯è¯»
- å¯ä»¥æ‰‹åŠ¨ä¿®æ”¹å’Œé‡æ–°æ‰§è¡Œ
- æ—¥å¿—æ–‡ä»¶ç»Ÿä¸€ç®¡ç†

### âœ… æ•°æ®åº“ + æ–‡ä»¶åŒé‡è®°å½•
- æ•°æ®åº“è®°å½•è®­ç»ƒçŠ¶æ€å’Œè¿›åº¦
- æ–‡ä»¶ç³»ç»Ÿä¿å­˜å®Œæ•´çš„è®­ç»ƒé…ç½®
- ä¸¤ç§æ–¹å¼äº’ä¸ºå¤‡ä»½

è¿™ç§è®¾è®¡æ—¢æ»¡è¶³äº†ç¨‹åºåŒ–çš„è‡ªåŠ¨æ‰§è¡Œéœ€æ±‚ï¼Œåˆæä¾›äº†ç”¨æˆ·å‹å¥½çš„æ‰‹åŠ¨æ“ä½œèƒ½åŠ›ï¼