#!/usr/bin/env python3

import os
import json
import shutil
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Literal
from datetime import datetime
import uuid
from terminal_service import log_info, log_error, log_success, log_progress
from PIL import Image
import threading

class Dataset:
    """æ•°æ®é›†ç±»"""

    def __init__(self, dataset_id: str, name: str, description: str = "", created_time: str = None):
        self.dataset_id = dataset_id
        self.name = name
        self.description = description
        self.created_time = created_time or datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        self.modified_time = self.created_time
        self.images = {}  # {image_filename: label_text}
        self.tags = []  # æ•°æ®é›†æ ‡ç­¾

    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'dataset_id': self.dataset_id,
            'name': self.name,
            'description': self.description,
            'created_time': self.created_time,
            'modified_time': self.modified_time,
            'images': self.images,
            'tags': self.tags
        }

    @classmethod
    def from_dict(cls, data: dict):
        """ä»å­—å…¸åˆ›å»º"""
        dataset = cls(
            dataset_id=data['dataset_id'],
            name=data['name'],
            description=data.get('description', ''),
            created_time=data.get('created_time')
        )
        dataset.modified_time = data.get('modified_time', dataset.created_time)
        dataset.images = data.get('images', {})
        dataset.tags = data.get('tags', [])
        return dataset

    def get_stats(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total = len(self.images)
        labeled = len([label for label in self.images.values() if label.strip()])
        return {
            'total': total,
            'labeled': labeled,
            'unlabeled': total - labeled,
            'completion_rate': round(labeled / total * 100) if total > 0 else 0
        }

    def add_image(self, image_path: str, label: str = "") -> bool:
        """æ·»åŠ å›¾ç‰‡åˆ°æ•°æ®é›†"""
        try:
            filename = os.path.basename(image_path)
            self.images[filename] = label
            self.modified_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            return True
        except Exception as e:
            log_error(f"æ·»åŠ å›¾ç‰‡å¤±è´¥: {e}")
            return False

    def update_label(self, filename: str, label: str):
        """æ›´æ–°æ ‡ç­¾"""
        if filename in self.images:
            self.images[filename] = label
            self.modified_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            return True
        return False

    def remove_image(self, filename: str) -> bool:
        """ç§»é™¤å›¾ç‰‡"""
        if filename in self.images:
            del self.images[filename]
            self.modified_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            return True
        return False


class DatasetManager:
    """æ•°æ®é›†ç®¡ç†å™¨"""
    def __init__(self, datasets_dir: str = "datasets"):
        # ç»Ÿä¸€å·¥ä½œæ ¹ï¼ˆå¯ä»è®¾ç½®æ³¨å…¥ï¼‰
        self.workspace_root = os.path.abspath("./workspace")
        self.medium_max_side = 1280
        self.web_strategy = "assets"
        self.assets_base_url = "assets"
        self.static_base_url = "/files"

        # æ•°æ®é›†æ ¹ï¼šworkspace/datasets
        self.datasets_dir = Path(self.workspace_root) / "datasets"
        self.datasets_dir.mkdir(parents=True, exist_ok=True)

        # é…ç½®ç›®å½•ï¼šworkspace/datasets/configs
        self.config_dir = self.datasets_dir / "configs"
        self.config_dir.mkdir(parents=True, exist_ok=True)

        self.datasets: Dict[str, Dataset] = {}
        self.load_datasets()


    def create_dataset(self, name: str, description: str = "") -> Tuple[bool, str]:
        """åˆ›å»ºæ–°æ•°æ®é›†"""
        try:
            # æ£€æŸ¥åç§°æ˜¯å¦å·²å­˜åœ¨
            if any(ds.name == name for ds in self.datasets.values()):
                return False, "æ•°æ®é›†åç§°å·²å­˜åœ¨"

            dataset_id = str(uuid.uuid4())
            dataset = Dataset(dataset_id, name, description)

            # åˆ›å»ºæ ‡å‡†ç›®å½•
            Path(self.get_images_dir(dataset_id)).mkdir(parents=True, exist_ok=True)
            Path(self.get_medium_dir(dataset_id)).mkdir(parents=True, exist_ok=True)

            self.datasets[dataset_id] = dataset
            self.save_dataset(dataset_id)

            log_success(f"åˆ›å»ºæ•°æ®é›†æˆåŠŸ: {name}")
            return True, f"æ•°æ®é›† '{name}' åˆ›å»ºæˆåŠŸ"

        except Exception as e:
            log_error(f"åˆ›å»ºæ•°æ®é›†å¤±è´¥: {e}")
            return False, f"åˆ›å»ºå¤±è´¥: {str(e)}"

    def delete_dataset(self, dataset_id: str) -> Tuple[bool, str]:
        """åˆ é™¤æ•°æ®é›†"""
        try:
            if dataset_id not in self.datasets:
                return False, "æ•°æ®é›†ä¸å­˜åœ¨"

            dataset_name = self.datasets[dataset_id].name

            # åˆ é™¤é…ç½®æ–‡ä»¶
            config_file = self.config_dir / f"{dataset_id}.json"
            if config_file.exists():
                config_file.unlink()

            # åˆ é™¤å›¾ç‰‡ç›®å½•
            dataset_dir = Path(self.get_dataset_path(dataset_id))
            if dataset_dir.exists():
                shutil.rmtree(dataset_dir)

            # ä»å†…å­˜ä¸­åˆ é™¤
            del self.datasets[dataset_id]

            log_success(f"åˆ é™¤æ•°æ®é›†æˆåŠŸ: {dataset_name}")
            return True, f"æ•°æ®é›† '{dataset_name}' åˆ é™¤æˆåŠŸ"

        except Exception as e:
            log_error(f"åˆ é™¤æ•°æ®é›†å¤±è´¥: {e}")
            return False, f"åˆ é™¤å¤±è´¥: {str(e)}"

    def get_dataset(self, dataset_id: str) -> Optional[Dataset]:
        """è·å–æ•°æ®é›†"""
        return self.datasets.get(dataset_id)

    def list_datasets(self) -> List[Dataset]:
        """è·å–æ‰€æœ‰æ•°æ®é›†åˆ—è¡¨"""
        return list(self.datasets.values())

    def save_dataset(self, dataset_id: str) -> bool:
        """ä¿å­˜æ•°æ®é›†é…ç½®"""
        try:
            if dataset_id not in self.datasets:
                return False

            dataset = self.datasets[dataset_id]
            config_file = self.config_dir / f"{dataset_id}.json"

            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(dataset.to_dict(), f, ensure_ascii=False, indent=2)

            return True

        except Exception as e:
            log_error(f"ä¿å­˜æ•°æ®é›†å¤±è´¥: {e}")
            return False

    def load_datasets(self):
        """åŠ è½½æ‰€æœ‰æ•°æ®é›†"""
        try:
            self.datasets.clear()

            for config_file in self.config_dir.glob("*.json"):
                try:
                    with open(config_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)

                    dataset = Dataset.from_dict(data)

                    # â€”â€” æ–°å¢ï¼šæŠŠå†å²é‡Œå¸¦è·¯å¾„çš„ key ç»Ÿä¸€æˆæ–‡ä»¶å â€”â€” #
                    fixed = {}
                    changed = False
                    for k, v in dataset.images.items():
                        fn = os.path.basename(k)
                        if fn != k:
                            changed = True
                        fixed[fn] = v
                    dataset.images = fixed
                    if changed:
                        # ç«‹åˆ»è½ç›˜ï¼Œé¿å…ä¸‹æ¬¡å†ä¿®
                        self.save_dataset(dataset.dataset_id)

                    self.datasets[dataset.dataset_id] = dataset

                except Exception as e:
                    log_error(f"åŠ è½½æ•°æ®é›†é…ç½®å¤±è´¥ {config_file}: {e}")

            log_info(f"åŠ è½½äº† {len(self.datasets)} ä¸ªæ•°æ®é›†")

        except Exception as e:
            log_error(f"åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")

    def import_images_to_dataset(self, dataset_id: str, image_files: List[str]) -> Tuple[int, str]:
        """å¯¼å…¥å›¾ç‰‡åˆ°æ•°æ®é›†"""
        try:
            if dataset_id not in self.datasets:
                return 0, "æ•°æ®é›†ä¸å­˜åœ¨"

            dataset = self.datasets[dataset_id]
            dataset_images_dir = Path(self.get_images_dir(dataset_id))

            success_count = 0
            supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp'}

            for image_path in image_files:
                try:
                    if not os.path.exists(image_path):
                        continue

                    file_ext = Path(image_path).suffix.lower()
                    if file_ext not in supported_formats:
                        continue

                    filename = os.path.basename(image_path)
                    dest_path = dataset_images_dir / filename

                    # å¦‚æœæ–‡ä»¶åé‡å¤ï¼Œæ·»åŠ æ—¶é—´æˆ³
                    if dest_path.exists():
                        name_part = Path(filename).stem
                        ext_part = Path(filename).suffix
                        timestamp = int(time.time())
                        filename = f"{name_part}_{timestamp}{ext_part}"
                        dest_path = dataset_images_dir / filename

                    # å¤åˆ¶å›¾ç‰‡æ–‡ä»¶
                    shutil.copy2(image_path, dest_path)

                    # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶
                    label_text = ""
                    txt_path = os.path.splitext(image_path)[0] + '.txt'
                    if os.path.exists(txt_path):
                        try:
                            with open(txt_path, 'r', encoding='utf-8') as f:
                                label_text = f.read().strip()
                        except Exception:
                            pass

                    # æ·»åŠ åˆ°æ•°æ®é›†
                    dataset.add_image(filename, label_text)
                    success_count += 1

                except Exception as e:
                    log_error(f"å¯¼å…¥å›¾ç‰‡å¤±è´¥ {image_path}: {e}")
                    continue

            if success_count > 0:
                self.save_dataset(dataset_id)
                log_success(f"æˆåŠŸå¯¼å…¥ {success_count} å¼ å›¾ç‰‡åˆ°æ•°æ®é›†")

            return success_count, f"æˆåŠŸå¯¼å…¥ {success_count} å¼ å›¾ç‰‡"

        except Exception as e:
            log_error(f"å¯¼å…¥å›¾ç‰‡å¤±è´¥: {e}")
            return 0, f"å¯¼å…¥å¤±è´¥: {str(e)}"

    def export_dataset(self, dataset_id: str, export_path: str, format_type: str = "folder") -> Tuple[bool, str]:
        """å¯¼å‡ºæ•°æ®é›†"""
        try:
            if dataset_id not in self.datasets:
                return False, "æ•°æ®é›†ä¸å­˜åœ¨"

            dataset = self.datasets[dataset_id]
            export_path = Path(export_path)

            if format_type == "folder":
                # å¯¼å‡ºä¸ºæ–‡ä»¶å¤¹æ ¼å¼ (å›¾ç‰‡+txt)
                dataset_export_dir = export_path / f"{dataset.name}_{dataset_id[:8]}"
                dataset_export_dir.mkdir(parents=True, exist_ok=True)

                dataset_images_dir = Path(self.get_images_dir(dataset_id))

                for filename, label in dataset.images.items():
                    # å¤åˆ¶å›¾ç‰‡
                    src_image = dataset_images_dir / filename
                    if src_image.exists():
                        shutil.copy2(src_image, dataset_export_dir / filename)

                        # ä¿å­˜æ ‡ç­¾
                        txt_filename = os.path.splitext(filename)[0] + '.txt'
                        txt_path = dataset_export_dir / txt_filename
                        with open(txt_path, 'w', encoding='utf-8') as f:
                            f.write(label)

                return True, f"æ•°æ®é›†å·²å¯¼å‡ºåˆ°: {dataset_export_dir}"

            elif format_type == "json":
                # å¯¼å‡ºä¸ºJSONæ ¼å¼
                json_file = export_path / f"{dataset.name}_{dataset_id[:8]}.json"

                export_data = {
                    'dataset_info': dataset.to_dict(),
                    'export_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }

                with open(json_file, 'w', encoding='utf-8') as f:
                    json.dump(export_data, f, ensure_ascii=False, indent=2)

                return True, f"æ•°æ®é›†å·²å¯¼å‡ºåˆ°: {json_file}"

            else:
                return False, "ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼"

        except Exception as e:
            log_error(f"å¯¼å‡ºæ•°æ®é›†å¤±è´¥: {e}")
            return False, f"å¯¼å‡ºå¤±è´¥: {str(e)}"

    def get_dataset_image_path(self, dataset_id: str, filename: str) -> Optional[str]:
        """è·å–æ•°æ®é›†ä¸­å›¾ç‰‡çš„å®Œæ•´è·¯å¾„"""
        dataset_images_dir = Path(self.get_images_dir(dataset_id))
        image_path = dataset_images_dir / filename
        return str(image_path) if image_path.exists() else None

    def update_dataset_label(self, dataset_id: str, filename: str, label: str) -> bool:
        """æ›´æ–°æ•°æ®é›†ä¸­çš„æ ‡ç­¾"""
        if dataset_id in self.datasets:
            result = self.datasets[dataset_id].update_label(filename, label)
            if result:
                self.save_dataset(dataset_id)
            return result
        return False

    def batch_update_labels(self, dataset_id: str, labels_dict: Dict[str, str]) -> Tuple[int, str]:
        """æ‰¹é‡æ›´æ–°æ ‡ç­¾"""
        try:
            if dataset_id not in self.datasets:
                return 0, "æ•°æ®é›†ä¸å­˜åœ¨"

            dataset = self.datasets[dataset_id]
            success_count = 0

            for filename, label in labels_dict.items():
                if dataset.update_label(filename, label):
                    success_count += 1

            if success_count > 0:
                self.save_dataset(dataset_id)
                log_success(f"æ‰¹é‡æ›´æ–°äº† {success_count} ä¸ªæ ‡ç­¾")

            return success_count, f"æˆåŠŸæ›´æ–° {success_count} ä¸ªæ ‡ç­¾"

        except Exception as e:
            log_error(f"æ‰¹é‡æ›´æ–°æ ‡ç­¾å¤±è´¥: {e}")
            return 0, f"æ›´æ–°å¤±è´¥: {str(e)}"

    def search_datasets(self, keyword: str) -> List[Dataset]:
        """æœç´¢æ•°æ®é›†"""
        if not keyword:
            return self.list_datasets()

        keyword = keyword.lower()
        results = []

        for dataset in self.datasets.values():
            if (keyword in dataset.name.lower() or
                    keyword in dataset.description.lower() or
                    keyword in ' '.join(dataset.tags).lower()):
                results.append(dataset)

        return results

    # ---- è·¯å¾„åŸºç¡€ ----
    def get_dataset_path(self, dataset_id: str) -> str:
        return os.path.join(self.workspace_root, "datasets", dataset_id)

    def get_images_dir(self, dataset_id: str) -> str:
        return os.path.join(self.get_dataset_path(dataset_id), "images")

    def get_medium_dir(self, dataset_id: str) -> str:
        return os.path.join(self.get_dataset_path(dataset_id), "medium")

    def list_images(self, dataset_id: str) -> list[str]:
        """ä»…è¿”å› images/ ä¸‹çš„æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰"""
        d = self.get_images_dir(dataset_id)
        if not os.path.isdir(d):
            return []
        return sorted([f for f in os.listdir(d)
                       if os.path.isfile(os.path.join(d, f))])

    def _need_medium(self, src_path: str) -> bool:
        try:
            with Image.open(src_path) as im:
                w, h = im.size
            return max(w, h) > int(self.medium_max_side)
        except Exception:
            return False  # è¯»ä¸åˆ°å°±å½“ä¸éœ€è¦ï¼ŒUIä¼šå›é€€åŸå›¾

    def ensure_medium(self, dataset_id: str, filename: str) -> str:
        """
        è¿”å›ä¸­æ¸…æ™°åº¦å›¾çš„ç»å¯¹è·¯å¾„ï¼š
        - è‹¥åŸå›¾å°ºå¯¸ <= é˜ˆå€¼ï¼šç›´æ¥è¿”å›åŸå›¾è·¯å¾„ï¼ˆä¸ç”Ÿæˆ mediumï¼‰
        - è‹¥ > é˜ˆå€¼ï¼šåœ¨ medium/ ä¸‹ç”Ÿæˆ JPEGï¼ˆæœ€é•¿è¾¹=é˜ˆå€¼ï¼‰ï¼Œå¹¶è¿”å›å…¶è·¯å¾„
        """
        src = os.path.join(self.get_images_dir(dataset_id), filename)
        if not os.path.exists(src):
            return src  # è®©ä¸Šå±‚è‡ªå·±å¤„ç†ä¸å­˜åœ¨

        if not self._need_medium(src):
            return src  # å°å›¾ç›´æ¥ç”¨åŸå›¾ä½œä¸ºä¸­å›¾

        os.makedirs(self.get_medium_dir(dataset_id), exist_ok=True)
        name, _ = os.path.splitext(filename)
        # ç”¨ mtime åšç‰ˆæœ¬å·ï¼Œæºå›¾æ›´æ–°ä¼šæ¢æ–‡ä»¶å
        mtime = int(os.path.getmtime(src))
        medium_path = os.path.join(self.get_medium_dir(dataset_id), f"{name}.{mtime}.jpg")

        # æ¸…ç†æ—§ç‰ˆæœ¬
        prefix = f"{name}."
        for f in os.listdir(self.get_medium_dir(dataset_id)):
            if f.startswith(prefix) and f != os.path.basename(medium_path):
                try:
                    os.remove(os.path.join(self.get_medium_dir(dataset_id), f))
                except:
                    pass

        # ç”Ÿæˆï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰
        if not os.path.exists(medium_path):
            with Image.open(src) as im:
                im.thumbnail((self.medium_max_side, self.medium_max_side), Image.Resampling.LANCZOS)
                if im.mode != "RGB":
                    im = im.convert("RGB")
                im.save(medium_path, "JPEG", quality=80, optimize=True, progressive=True)

        return medium_path

    def path_for(self, dataset_id: str, filename: str, kind: Literal["images", "medium"]) -> str:
        """
        è¿”å›æœ¬åœ°æ–‡ä»¶çš„ file:// URIï¼ŒFlet æ¡Œé¢ç«¯å¯¹ URI æ›´ç¨³å®šã€‚
        kind: "images" åŸå›¾ï¼›"medium" ä¸­æ¸…æ™°åº¦ï¼ˆå†…éƒ¨ä¼šè‡ªåŠ¨æŒ‰é˜ˆå€¼ç”Ÿæˆæˆ–å›é€€åŸå›¾ï¼‰
        """
        if kind == "images":
            p = os.path.join(self.get_images_dir(dataset_id), filename)
        else:
            p = self.ensure_medium(dataset_id, filename)  # å°å›¾ä¼šç›´æ¥å›é€€åŸå›¾è·¯å¾„
        # ç»Ÿä¸€è§„èŒƒåŒ–ä¸º file:// URI
        return Path(p).resolve().as_uri()

    # dataset_manager.py ä¸­ç¡®è®¤è¿™ä¸ªæ–¹æ³•
    def url_for(self, dataset_id: str, filename: str, kind: Literal["images", "medium"]) -> Optional[str]:
        """Webç«¯ä¸“ç”¨ï¼šè¿”å›ç›¸å¯¹äº assets_dir çš„è·¯å¾„"""
        if kind == "images":
            abs_path = os.path.join(self.get_images_dir(dataset_id), filename)
        else:
            abs_path = self.ensure_medium(dataset_id, filename)

        if not os.path.exists(abs_path):
            return None

        # å…³é”®ï¼šç¡®ä¿è¿”å›æ ¼å¼æ˜¯ "datasets/abc123/images/photo.jpg"
        abs_path_norm = os.path.normpath(abs_path).replace("\\", "/")
        ws_root = os.path.normpath(self.workspace_root).replace("\\", "/")

        if abs_path_norm.startswith(ws_root):
            rel = abs_path_norm[len(ws_root):].lstrip("/")
            return rel  # ğŸ”¥ ä¸è¦åŠ  "assets/" å‰ç¼€
        return None





